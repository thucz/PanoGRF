import torch
import torch.nn as nn
import torch.nn.functional as F
from network.ops import interpolate_feats, SSIM
import os
import matplotlib.pyplot as plt

class Loss:
    def __init__(self, keys):
        """
        keys are used in multi-gpu model, DummyLoss in train_tools.py
        :param keys: the output keys of the dict
        """
        self.keys=keys

    def __call__(self, data_pr, data_gt, step, **kwargs):
        pass

class ConsistencyLoss(Loss):
    default_cfg={
        'use_ray_mask': False,
        'use_dr_loss': False,
        'use_dr_fine_loss': False,
        'use_nr_fine_loss': False,
    }
    def __init__(self, cfg):
        self.cfg={**self.default_cfg,**cfg}
        super().__init__([f'loss_prob','loss_prob_fine'])

    def __call__(self, data_pr, data_gt, step, **kwargs):
        if 'hit_prob_self' not in data_pr: return {}
        prob0 = data_pr['hit_prob_nr'].detach()     # qn,rn,dn
        prob1 = data_pr['hit_prob_self']            # qn,rn,dn
        if self.cfg['use_ray_mask']:
            ray_mask = data_pr['ray_mask'].float()  # 1,rn
        else:
            ray_mask = 1
        ce = - prob0 * torch.log(prob1 + 1e-5) - (1 - prob0) * torch.log(1 - prob1 + 1e-5)
        outputs={'loss_prob': torch.mean(torch.mean(ce,-1),1)}
        
        if 'hit_prob_nr_fine' in data_pr:
            prob0 = data_pr['hit_prob_nr_fine'].detach()     # qn,rn,dn
            prob1 = data_pr['hit_prob_self_fine']            # qn,rn,dn
            ce = - prob0 * torch.log(prob1 + 1e-5) - (1 - prob0) * torch.log(1 - prob1 + 1e-5)
            outputs['loss_prob_fine']=torch.mean(torch.mean(ce,-1),1)
        return outputs

class RenderLoss(Loss):
    default_cfg={
        'use_ray_mask': True,
        'use_dr_loss': False,
        'use_dr_fine_loss': False,
        'use_nr_fine_loss': False,
    }
    def __init__(self, cfg):
        self.cfg={**self.default_cfg,**cfg}
        super().__init__([f'loss_rgb'])

    def __call__(self, data_pr, data_gt, step, **kwargs):
        rgb_gt = data_pr['pixel_colors_gt'] # 1,rn,3
        rgb_nr = data_pr['pixel_colors_nr'] # 1,rn,3
        def compute_loss(rgb_pr,rgb_gt):
            loss=torch.sum((rgb_pr-rgb_gt)**2,-1)        # b,n
            if self.cfg['use_ray_mask']:
                # import ipdb;ipdb.set_trace()
                ray_mask = data_pr['ray_mask'].float() # 1,rn                

                loss = torch.sum(loss*ray_mask,1)/(torch.sum(ray_mask,1)+1e-3)
            else:
                loss = torch.mean(loss, 1)
            return loss

        results = {'loss_rgb_nr': compute_loss(rgb_nr, rgb_gt)}
        if self.cfg['use_dr_loss']:
            rgb_dr = data_pr['pixel_colors_dr']  # 1,rn,3
            results['loss_rgb_dr'] = compute_loss(rgb_dr, rgb_gt)
        if self.cfg['use_dr_fine_loss']:
            results['loss_rgb_dr_fine'] = compute_loss(data_pr['pixel_colors_dr_fine'], rgb_gt)
        if self.cfg['use_nr_fine_loss']:
            results['loss_rgb_nr_fine'] = compute_loss(data_pr['pixel_colors_nr_fine'], rgb_gt)
        return results

class DepthLoss(Loss):
    default_cfg={
        'depth_correct_thresh': 0.02,
        'depth_loss_type': 'l2',
        'depth_loss_l1_beta': 0.05,
    }
    def __init__(self, cfg):
        super().__init__(['loss_depth'])
        self.cfg={**self.default_cfg,**cfg}
        if self.cfg['depth_loss_type']=='smooth_l1':
            self.loss_op=nn.SmoothL1Loss(reduction='none',beta=self.cfg['depth_loss_l1_beta'])

    def __call__(self, data_pr, data_gt, step, **kwargs):
        if 'true_depth' not in data_gt['ref_imgs_info']:
            return {'loss_depth': torch.zeros([1], dtype=torch.float32, device=data_pr['pixel_colors_nr'].device)}
            
        coords = data_pr['depth_coords'] # rfn,pn,2
        depth_pr = data_pr['depth_mean'] # rfn,pn
        depth_maps = data_gt['ref_imgs_info']['true_depth'] # rfn,1,h,w
        rfn, _, h, w = depth_maps.shape
        depth_gt = interpolate_feats(
            depth_maps, coords, h, w, padding_mode='border', align_corners=True)[...,0]   # rfn, pn

        # transform to inverse depth coordinate
        depth_range = data_gt['ref_imgs_info']['depth_range'] # rfn,2
        near, far = -1/depth_range[:,0:1], -1/depth_range[:,1:2] # rfn,1
        def process(depth):
            depth = torch.clamp(depth, min=1e-5)
            depth = -1 / depth
            depth = (depth - near) / (far - near)
            depth = torch.clamp(depth, min=0, max=1.0)
            return depth

        depth_gt = process(depth_gt)

        # compute loss
        def compute_loss(depth_pr):
            if self.cfg['depth_loss_type']=='l2':
                loss = (depth_gt - depth_pr)**2
            elif self.cfg['depth_loss_type']=='smooth_l1':
                loss = self.loss_op(depth_gt, depth_pr)

            # if data_gt['scene_name'].startswith('gso'):
            #     depth_maps_noise = data_gt['ref_imgs_info']['depth']  # rfn,1,h,w
            #     depth_aug = interpolate_feats(depth_maps_noise, coords, h, w, padding_mode='border', align_corners=True)[..., 0]  # rfn,pn
            #     depth_aug = process(depth_aug)
            #     mask = (torch.abs(depth_aug-depth_gt)<self.cfg['depth_correct_thresh']).float()
            #     loss = torch.sum(loss * mask, 1) / (torch.sum(mask, 1) + 1e-4)
            # else:
            loss = torch.mean(loss, 1)
            return loss

        outputs = {'loss_depth': compute_loss(depth_pr)}
        if 'depth_mean_fine' in data_pr:
            outputs['loss_depth_fine'] = compute_loss(data_pr['depth_mean_fine'])
        return outputs


class AELoss(Loss):
    default_cfg={
    
    }
    def __init__(self, cfg):
        self.cfg={**self.default_cfg,**cfg}
        super().__init__([f'loss_ae'])
        self.count = 0
        self.ssim = SSIM()

    def __call__(self, data_pr, data_gt, step, **kwargs):
        ae_outputs = data_pr["ae_outputs"]
        ray_ae_outputs = data_pr["ray_ae_outputs"]
        # data_pr["ref_img"]
        data_gt["ref_imgs_info"]
        # import ipdb;ipdb.set_trace()
        loss_ae = self.compute_losses(ae_outputs, data_gt, "image_encoder")
        loss_ray_ae = self.compute_losses(ray_ae_outputs, data_gt, "ray_image_encoder")
        
        results = {'loss_ae':loss_ae, "loss_ray_ae": loss_ray_ae}




        # rgb_gt = data_pr['pixel_colors_gt'] # 1,rn,3
        # rgb_nr = data_pr['pixel_colors_nr'] # 1,rn,3
        # def compute_loss(rgb_pr,rgb_gt):
        #     loss=torch.sum((rgb_pr-rgb_gt)**2,-1)        # b,n
        #     if self.cfg['use_ray_mask']:
        #         # import ipdb;ipdb.set_trace()
        #         ray_mask = data_pr['ray_mask'].float() # 1,rn                

        #         loss = torch.sum(loss*ray_mask,1)/(torch.sum(ray_mask,1)+1e-3)
        #     else:
        #         loss = torch.mean(loss, 1)
        #     return loss

        # results = {'loss_rgb_nr': compute_loss(rgb_nr, rgb_gt)}
        # if self.cfg['use_dr_loss']:
        #     rgb_dr = data_pr['pixel_colors_dr']  # 1,rn,3
        #     results['loss_rgb_dr'] = compute_loss(rgb_dr, rgb_gt)
        # if self.cfg['use_dr_fine_loss']:
        #     results['loss_rgb_dr_fine'] = compute_loss(data_pr['pixel_colors_dr_fine'], rgb_gt)
        # if self.cfg['use_nr_fine_loss']:
        #     results['loss_rgb_nr_fine'] = compute_loss(data_pr['pixel_colors_nr_fine'], rgb_gt)
        
        return results

    def robust_l1(self, pred, target):
        eps = 1e-3
        return torch.sqrt(torch.pow(target - pred, 2) + eps ** 2)

    def compute_reprojection_loss(self, pred, target):
        photometric_loss = self.robust_l1(pred, target).mean(1, True)
        ssim_loss = self.ssim(pred, target).mean(1, True)
        reprojection_loss = (0.85 * ssim_loss + 0.15 * photometric_loss)
        return reprojection_loss

    def compute_losses(self, outputs, inputs, prefix=None):
        # loss_ae = self.compute_losses(ae_outputs, data_gt)
        # loss_ray_ae = self.compute_losses(ray_ae_outputs, data_gt)

        loss_dict = {}
        interval = 1000
        target = inputs["ref_imgs_info"]["imgs"]#2, 3, h, w
        batch_size = target.shape[0]

        # for i in range(5):
        #     f=features[i]
        #     smooth_loss = self.get_smooth_loss(f, target)
        #     loss_dict[('smooth_loss', i)] = smooth_loss/ (2 ** i)/5
        scales = [0, 1, 2, 3]
        os.makedirs(os.path.join('data/model', self.cfg['name'], prefix), exist_ok=True)




        for scale in scales:
            """
            initialization
            """
            pred = outputs[("pred_img", scale)]
            # import ipdb;ipdb.set_trace()
            _,_,h,w = pred.size()
            target = F.interpolate(target, [h, w], mode="bilinear", align_corners=False)
            min_reconstruct_loss = self.compute_reprojection_loss(pred, target)
            loss_dict[('min_reconstruct_loss', scale)] = min_reconstruct_loss.reshape(batch_size, -1).mean(dim=1)/len(scales)

            if self.count % interval == 0:
                # import ipdb;ipdb.set_trace()
                # os.path.join('data/model', self.cfg['name'], 'auto')         
                img_path = os.path.join('data/model', self.cfg['name'], prefix, 'auto_{:0>4d}_{}.png'.format(self.count // interval, scale))
                plt.imsave(img_path, pred[0].transpose(0,1).transpose(1,2).data.cpu().numpy())
                img_path = os.path.join('data/model', self.cfg['name'], prefix, 'img_{:0>4d}_{}.png'.format(self.count // interval, scale))
                plt.imsave(img_path, target[0].transpose(0, 1).transpose(1, 2).data.cpu().numpy())
        # loss = sum(_value for _key, _value in loss_dict.items())
        min_reconstruct_loss = torch.zeros((batch_size)).cuda()
        # import ipdb;ipdb.set_trace()
        for _key, _value in loss_dict.items():
            min_reconstruct_loss += _value
        self.count += 1
        return min_reconstruct_loss

name2loss={
    'render': RenderLoss,
    'depth': DepthLoss,
    'consist': ConsistencyLoss,
    'autoencoder': AELoss,
}